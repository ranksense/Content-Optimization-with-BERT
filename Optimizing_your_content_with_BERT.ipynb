{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optimizing_your_content_with_BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ddb9DEzci4Eu",
        "colab_type": "text"
      },
      "source": [
        "# How to Optimize Your Content for Search Questions using Deep Learning\n",
        "\n",
        "In this notebook, we will be testing BERT for Question Answering. \n",
        "\n",
        "BERT powers recent breakthrough advancements in how major search engines understand what users search for.\n",
        "\n",
        "This is a company to Hamlet Batista's article in the [Bing Webmaster Blog](https://blogs.bing.com/webmaster/july-2020/How-to-Optimize-Your-Content-for-Search-Questions-using-Deep-Learning) \n",
        "\n",
        "Notebook prepared by [Anirudh Tatavarthi](https://www.linkedin.com/in/anirudh-tatavarthi-5840b31a8/), Tech Support Intern at [RankSense](https://www.ranksense.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExO6QTfYVS-4",
        "colab_type": "text"
      },
      "source": [
        "## Testing BERT Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hc5sl4MZoDw",
        "colab_type": "text"
      },
      "source": [
        "First, we will test BERT question answering by entering a question based off of manually written context. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4RkN3j2Tddp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#install the necessary libraries and imports\n",
        "!pip install transformers==2.4.1\n",
        "from transformers import pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yByACjWTl4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run this block to see how it works\n",
        "nlp = pipeline('question-answering')\n",
        "\n",
        "nlp({\n",
        "    'question': 'What is the name of the repository ?',\n",
        "    'context': 'Pipeline have been included in the huggingface/transformers repository'\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlwZ4WCIWBrY",
        "colab_type": "text"
      },
      "source": [
        "The output should consist of an answer, a score (the confidence in the answer), and the starting and ending indicies in the source context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cf_qIK7Xer5",
        "colab_type": "text"
      },
      "source": [
        "## Testing BERT Question Answering on Your Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsjh0AwWXe2_",
        "colab_type": "text"
      },
      "source": [
        "We will test BERT by asking a question and feeding the text of an entire blog as the context. **(You will to copy the CSS selector to scrape the body of the post)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VJ07JVxXrR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This is necessary to scrape the body text of your web page\n",
        "!pip install requests-html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ECdcXFiXt6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run this block to see how it works\n",
        "from requests_html import HTMLSession\n",
        "session = HTMLSession()\n",
        "\n",
        "url = \"https://azure.microsoft.com/en-us/blog/bing-delivers-its-largest-improvement-in-search-experience-using-azure-gpus/\"\n",
        "\n",
        "selector = \"#main > div > div.row.row-size2 > div.column.medium-8 > article > div:nth-child(1) > div.blog-postContent\"\n",
        "\n",
        "with session.get(url) as r:\n",
        "  post = r.html.find(selector, first=True)\n",
        "  text = post.text\n",
        "\n",
        "# Allocate a pipeline for question-answering\n",
        "nlp = pipeline('question-answering')\n",
        "\n",
        "nlp({\n",
        "    'question': 'When did Bing start using using BERT?',\n",
        "    'context': text\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE4mzYhzX4t0",
        "colab_type": "text"
      },
      "source": [
        "You can click on the link for yourself to double check the answer given by BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5H74BFCYO2g",
        "colab_type": "text"
      },
      "source": [
        "## Test the similarity of a list of words with no context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31MBZROsYW8z",
        "colab_type": "text"
      },
      "source": [
        "By simply feeding a list of words, you can see how embeddings gauge the similarity or relationship between each of the words. This is called **context-free embeddings**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRAXeeq3Ypcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Install the necessary packages\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpPLGBjYZ7Dq",
        "colab_type": "text"
      },
      "source": [
        "**You may have to navigate to \"Runtime>Restart and run all\" in order to avoid any errors for the next block of code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dTL12ZDYth8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run this block to see how it works\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg') \n",
        "\n",
        "tokens = nlp(u'computer laptop mouse house')\n",
        " \n",
        "for token1 in tokens:\n",
        "    for token2 in tokens:\n",
        "        print(token1.text, token2.text, token1.similarity(token2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DuO6jy6ZbFi",
        "colab_type": "text"
      },
      "source": [
        "Notice how computer and laptop have a higher similarity rating than mouse and house, despite mouse and house looking and sounding similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSa0kp8maJb1",
        "colab_type": "text"
      },
      "source": [
        "## Test the similarity of two words with context\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE91llSJakCW",
        "colab_type": "text"
      },
      "source": [
        "This time, let's test **context-aware embeddings** by viewing the similarity between the word \"Lincoln\" used in two sentences with different contexts.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnMfPn4CcvQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#install the necessary packages\n",
        "!pip install spacy-transformers\n",
        "!python -m spacy download en_trf_bertbaseuncased_lg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oKQNFz1ebRK",
        "colab_type": "text"
      },
      "source": [
        "**You may have to navigate to \"Runtime>Restart and run all\" in order to avoid any errors for the next block of code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWgnbm2Ycza-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run this block to see how it works\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_trf_bertbaseuncased_lg\")\n",
        "\n",
        "tokens = nlp(u'I will take the Lincoln Tunnel to go to NYC. Abraham Lincoln was the 16th president of the United States')\n",
        " \n",
        "print(tokens[4].similarity(tokens[12]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0RKQrbEeLdy",
        "colab_type": "text"
      },
      "source": [
        "Notice how the similarity rating is not 1, despite comparing the same exact word. This is because both sentences are not referring to the same \"Lincoln\""
      ]
    }
  ]
}